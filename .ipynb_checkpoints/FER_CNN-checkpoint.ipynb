{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os, shutil\n",
    "from os import walk\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef5a64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1,\n",
    "    rescale=1.0/255,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95584aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67454 images belonging to 3 classes.\n",
      "Found 3175 images belonging to 3 classes.\n",
      "Found 15881 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = './images/'\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(base_path + \"train\",\n",
    "                                          target_size=(48,48),\n",
    "                                          batch_size=batch_size,\n",
    "                                          seed=42,\n",
    "                                          shuffle=False,\n",
    "                                          subset='training',\n",
    "                                          class_mode='categorical')\n",
    "val_generator = datagen.flow_from_directory(base_path + \"train\",\n",
    "                                        target_size=(48,48),\n",
    "                                        batch_size=batch_size,\n",
    "                                        seed=42,\n",
    "                                        shuffle=False,\n",
    "                                        subset='validation',\n",
    "                                        class_mode='categorical')\n",
    "test_generator = datagen.flow_from_directory(base_path + \"test\",\n",
    "                                        target_size=(48,48),\n",
    "                                        batch_size=batch_size,\n",
    "                                        seed=42,\n",
    "                                        shuffle=False,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd8868",
   "metadata": {},
   "source": [
    "**Simple NN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e068aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.applications import mobilenet_v2, VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0d3eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_29 (Conv2D)          (None, 46, 46, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 23, 23, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 23, 23, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 11, 11, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                495680    \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 534,595\n",
      "Trainable params: 534,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_leakyReku = Sequential()\n",
    "model_leakyReku.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 3)))\n",
    "model_leakyReku.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_leakyReku.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_leakyReku.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_leakyReku.add(Flatten())\n",
    "model_leakyReku.add(Dense(64, activation=layers.LeakyReLU(alpha=0.2)))\n",
    "\n",
    "# model_leakyReku.add(Dense(32, activation=layers.LeakyReLU(alpha=0.2)))\n",
    "\n",
    "model_leakyReku.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_leakyReku.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='sgd',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model_leakyReku.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57939805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 60s 594ms/step - loss: 1.1201 - accuracy: 0.2939 - val_loss: 1.1585 - val_accuracy: 9.3750e-04 - lr: 0.0100\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 56s 561ms/step - loss: 1.0850 - accuracy: 0.4530 - val_loss: 0.9217 - val_accuracy: 0.8555 - lr: 0.0100\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 1.1072 - accuracy: 0.3093 - val_loss: 1.0823 - val_accuracy: 0.1445 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "history_leakyReku = model_leakyReku.fit(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=100, #train_generator.n//train_generator.batch_size,\n",
    "                        epochs=3,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps = 50, # val_generator.n//val_generator.batch_size,\n",
    "                        callbacks=[\n",
    "                                keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "                                keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1)\n",
    "                                ]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ab146",
   "metadata": {},
   "source": [
    "### transfered NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('binary_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df125e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,887,363\n",
      "Trainable params: 172,675\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16, mobilenet_v2, resnet50\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Dropout \n",
    "\n",
    "base = VGG16(weights='imagenet', include_top=False, input_shape=(48,48,3))\n",
    "\n",
    "# Freeze convolutional layers\n",
    "for layer in base.layers:\n",
    "    layer.trainable = False  \n",
    "    \n",
    "NN_transfer = Sequential()\n",
    "NN_transfer.add(base)\n",
    "NN_transfer.add(Flatten())\n",
    "NN_transfer.add(Dense(256,   activation='relu'))\n",
    "NN_transfer.add(Dense(128,  activation='relu'))\n",
    "NN_transfer.add(Dense(64,  activation='relu'))\n",
    "NN_transfer.add(Dense(3, activation='softmax'))\n",
    "\n",
    "#Default Adam(lr=0.001) \n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "NN_transfer.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "NN_transfer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7616b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 27s 543ms/step - loss: 1.1675 - accuracy: 0.3919 - val_loss: 0.8723 - val_accuracy: 0.4094 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 1.1340 - accuracy: 0.3617 - val_loss: 1.1282 - val_accuracy: 0.2988 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 28s 560ms/step - loss: 1.1320 - accuracy: 0.2919 - val_loss: 1.1148 - val_accuracy: 0.3094 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 27s 540ms/step - loss: 1.0498 - accuracy: 0.4294 - val_loss: 0.8605 - val_accuracy: 0.4956 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 27s 545ms/step - loss: 1.1019 - accuracy: 0.4206 - val_loss: 0.8485 - val_accuracy: 0.6681 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 1.1002 - accuracy: 0.3931 - val_loss: 1.1040 - val_accuracy: 0.3288 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 1.0808 - accuracy: 0.4594 - val_loss: 0.9375 - val_accuracy: 0.5781 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.0662 - accuracy: 0.4219\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.0662 - accuracy: 0.4219 - val_loss: 0.9611 - val_accuracy: 0.4963 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 57s 1s/step - loss: 1.0767 - accuracy: 0.4269 - val_loss: 1.0516 - val_accuracy: 0.3506 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 59s 1s/step - loss: 1.0608 - accuracy: 0.4363 - val_loss: 1.0165 - val_accuracy: 0.3938 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_transfer = NN_transfer.fit(                       \n",
    "                        train_generator,\n",
    "                        steps_per_epoch=50,\n",
    "                        epochs=10,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps =50,\n",
    "                        callbacks=[\n",
    "                                keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "                                keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1)\n",
    "                                ]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ce1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a10abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_model_score(history):\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14,4))\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    ax1.plot(epochs, acc, label='Train Accuracy')\n",
    "    ax1.plot(epochs, val_acc, label='Val Accuracy')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(epochs, loss, label='Train Loss')\n",
    "    ax2.plot(epochs, val_loss, label='Val Loss')\n",
    "    ax2.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
